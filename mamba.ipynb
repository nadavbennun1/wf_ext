{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "71fb4389-9bba-4f9b-bac7-a7dc168e9fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Import the Mamba model\n",
    "from mamba_wf import Mamba, RMSNorm\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "122c5963-4629-499f-a896-d5f2c32a32fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data shape: torch.Size([100000, 11, 1])\n",
      "Target data shape: torch.Size([100000, 5])\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "x = torch.load('test_sims/x_phylo.pt')\n",
    "x = x.reshape(x.shape[0], x.shape[1], 1)\n",
    "theta = torch.load('test_sims/theta_phylo.pt')\n",
    "\n",
    "# Print shapes for verification\n",
    "print(\"Input data shape:\", x.shape)\n",
    "print(\"Target data shape:\", theta.shape)\n",
    "\n",
    "# Hyperparameters\n",
    "BATCH_SIZE = 100\n",
    "LEARNING_RATE = 1e-3\n",
    "EPOCHS = 5\n",
    "TRAIN_SPLIT = 0.9  # 90% for training, 10% for validation\n",
    "\n",
    "# Extract dimensions from the data\n",
    "n_samples = x.shape[0]\n",
    "seq_len = x.shape[1]\n",
    "theta_dim = theta.shape[1]\n",
    "d_model = 2\n",
    "state_size = 32\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "train_size = int(n_samples * TRAIN_SPLIT)\n",
    "train_x = x[:train_size]\n",
    "train_theta = theta[:train_size]\n",
    "val_x = x[train_size:]\n",
    "val_theta = theta[train_size:]\n",
    "\n",
    "# Create DataLoaders\n",
    "train_dataset = TensorDataset(train_x, train_theta)\n",
    "val_dataset = TensorDataset(val_x, val_theta)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c8df236d-b771-40bf-9e03-1ec41c7522ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to add a linear output layer to map from d_model to n_params (which is theta.shape[1])\n",
    "class MambaWithOutputLayer(nn.Module):\n",
    "    def __init__(self, seq_len, d_model, state_size, output_size, batch_size, device):\n",
    "        super(MambaWithOutputLayer, self).__init__()\n",
    "        self.mamba = Mamba(seq_len=seq_len, d_model=d_model, state_size=state_size, batch_size=batch_size, device=device)\n",
    "        self.output_layer = nn.Linear(d_model, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # The Mamba output has shape [batch_size, seq_len, d_model]\n",
    "        # We need to process it to get [batch_size, output_size]\n",
    "        x = self.mamba(x)\n",
    "        # Take the last timestep output for simplicity\n",
    "        x = x[:, -1, :]  # Shape: [batch_size, d_model]\n",
    "        x = self.output_layer(x)  # Shape: [batch_size, output_size]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fee125f9-8e43-4049-bc92-0f1e69ed305d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MambaWithOutputLayer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Create the model with output layer\u001b[39;00m\n\u001b[1;32m      2\u001b[0m n_params \u001b[38;5;241m=\u001b[39m train_theta\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m----> 3\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mMambaWithOutputLayer\u001b[49m(seq_len\u001b[38;5;241m=\u001b[39mseq_len, d_model\u001b[38;5;241m=\u001b[39md_model, state_size\u001b[38;5;241m=\u001b[39mstate_size, \n\u001b[1;32m      4\u001b[0m                             output_size\u001b[38;5;241m=\u001b[39mn_params, batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE, device\u001b[38;5;241m=\u001b[39mdevice)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Define loss function and optimizer\u001b[39;00m\n\u001b[1;32m      7\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mMSELoss()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'MambaWithOutputLayer' is not defined"
     ]
    }
   ],
   "source": [
    "# Create the model with output layer\n",
    "n_params = train_theta.shape[1]\n",
    "model = MambaWithOutputLayer(seq_len=seq_len, d_model=d_model, state_size=state_size, \n",
    "                            output_size=n_params, batch_size=BATCH_SIZE, device=device).to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# Training loop\n",
    "def train():\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        # Training\n",
    "        for inputs, targets in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS} - Training\"):\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            \n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            \n",
    "        epoch_train_loss = running_loss / len(train_loader.dataset)\n",
    "        train_losses.append(epoch_train_loss)\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        running_val_loss = 0.0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{EPOCHS} - Validation\"):\n",
    "                inputs = inputs.to(device)\n",
    "                targets = targets.to(device)\n",
    "                \n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                \n",
    "                running_val_loss += loss.item() * inputs.size(0)\n",
    "                \n",
    "        epoch_val_loss = running_val_loss / len(val_loader.dataset)\n",
    "        val_losses.append(epoch_val_loss)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{EPOCHS}, \"\n",
    "              f\"Train Loss: {epoch_train_loss:.4f}, \"\n",
    "              f\"Val Loss: {epoch_val_loss:.4f}\")\n",
    "        \n",
    "        # Save model checkpoint\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'train_loss': epoch_train_loss,\n",
    "                'val_loss': epoch_val_loss,\n",
    "            }, f'mamba_checkpoint_epoch_{epoch+1}.pt')\n",
    "    \n",
    "    return train_losses, val_losses\n",
    "\n",
    "# Plot training and validation loss\n",
    "def plot_loss(train_losses, val_losses):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(train_losses, label='Training Loss')\n",
    "    plt.plot(val_losses, label='Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig('loss_plot.png')\n",
    "    plt.close()\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "def evaluate():\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    all_outputs = []\n",
    "    all_targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in tqdm(val_loader, desc=\"Evaluating\"):\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            \n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "            \n",
    "            all_outputs.append(outputs.cpu().numpy())\n",
    "            all_targets.append(targets.cpu().numpy())\n",
    "    \n",
    "    # Calculate average loss\n",
    "    avg_val_loss = val_loss / len(val_loader.dataset)\n",
    "    print(f\"Validation Loss: {avg_val_loss:.4f}\")\n",
    "    \n",
    "    # Concatenate all outputs and targets\n",
    "    all_outputs = np.concatenate(all_outputs, axis=0)\n",
    "    all_targets = np.concatenate(all_targets, axis=0)\n",
    "    \n",
    "    return avg_val_loss\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Starting training...\")\n",
    "    train_losses, val_losses = train()\n",
    "    plot_loss(train_losses, val_losses)\n",
    "    \n",
    "    print(\"\\nEvaluating model...\")\n",
    "    avg_val_loss = evaluate()\n",
    "    \n",
    "    print(\"Training and evaluation completed. Model saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d141008-51a5-4491-be84-f90d849ffb17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 10/10 [00:00<00:00, 237.89it/s]\n"
     ]
    }
   ],
   "source": [
    "# Test the trained model on a test set from a specific simulator\n",
    "def test_mamba(sim):\n",
    "    # Load files and initialize datasets\n",
    "    test_x = torch.load(f'test_sims/test_x_{sim}.pt')\n",
    "    test_x = test_x.reshape(test_x.shape[0], test_x.shape[1], 1)\n",
    "    test_theta = torch.load(f'test_sims/test_theta_{sim}.pt')\n",
    "    test_dataset = TensorDataset(test_x, test_theta)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False) # Can't shuffle if you want meaningful results :)\n",
    "\n",
    "    # Begin evaluating\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "            for inputs, targets in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "                inputs = inputs.to(device)\n",
    "                targets = targets.to(device)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                predictions.append(outputs)\n",
    "\n",
    "    # Get all predictions\n",
    "    predictions = torch.cat(predictions)\n",
    "    torch.save(predictions, f'test_sims/predictions_{sim}_mamba_combined.pt')\n",
    "    \n",
    "    return predictions, test_theta\n",
    "\n",
    "for sim in ['combined']:\n",
    "    y = test_mamba(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d8232ba1-aa64-4db6-8fe3-5a8219ed2749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10740"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count parameters in the Mamba model\n",
    "# Specifically here I show the 2-mutation, therefore numbers are different from Table 1\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c6dd46-3d01-414f-b2a6-8d97c88e32ad",
   "metadata": {},
   "source": [
    "## Mamba Density Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7c510a57-ee48-4b69-b726-4883f549d14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import math\n",
    "class MambaDensityEstimator(nn.Module):\n",
    "    def __init__(self, seq_len, d_model, state_size, batch_size, device, num_components=10, theta_dim=2):\n",
    "        super().__init__()\n",
    "        self.mamba = Mamba(seq_len, d_model, state_size, batch_size, device)\n",
    "        self.num_components = num_components\n",
    "        self.theta_dim = theta_dim\n",
    "        self.device = device\n",
    "\n",
    "        self.L_param_count = theta_dim * (theta_dim + 1) // 2\n",
    "        out_dim = num_components * (1 + theta_dim + self.L_param_count)\n",
    "\n",
    "        self.output_proj = nn.Linear(d_model, out_dim, device=device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.mamba(x)\n",
    "        pooled = features.mean(dim=1)\n",
    "\n",
    "        raw_out = self.output_proj(pooled)  # (B, K * total)\n",
    "        raw_out = raw_out.view(-1, self.num_components, 1 + self.theta_dim + self.L_param_count)\n",
    "\n",
    "        logit_weights = raw_out[..., 0]                     # (B, K)\n",
    "        means = raw_out[..., 1 : 1 + self.theta_dim]        # (B, K, d)\n",
    "        L_flat = raw_out[..., 1 + self.theta_dim :]         # (B, K, d*(d+1)/2)\n",
    "\n",
    "        weights = F.softmax(logit_weights, dim=-1)\n",
    "        L = self._expand_cholesky(L_flat)                   # (B, K, d, d)\n",
    "        return weights, means, L\n",
    "\n",
    "    def _expand_cholesky(self, L_flat):\n",
    "        \"\"\"\n",
    "        Convert flat Cholesky params to lower-triangular matrices with positive diagonal.\n",
    "        L_flat: (B, K, d*(d+1)//2)\n",
    "        Returns: L: (B, K, d, d)\n",
    "        \"\"\"\n",
    "        B, K, _ = L_flat.shape\n",
    "        d = self.theta_dim\n",
    "        L = torch.zeros(B, K, d, d, device=L_flat.device)\n",
    "        tril_indices = torch.tril_indices(row=d, col=d, offset=0)\n",
    "\n",
    "        # Fill in lower triangle\n",
    "        L[:, :, tril_indices[0], tril_indices[1]] = L_flat\n",
    "\n",
    "        # Apply softplus + jitter to diagonals\n",
    "        diag_indices = torch.arange(d)\n",
    "        L[:, :, diag_indices, diag_indices] = F.softplus(L[:, :, diag_indices, diag_indices]) + 1e-2\n",
    "\n",
    "        return L\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0d74bad1-877b-4bee-8604-1e7934c901b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions import MultivariateNormal, MixtureSameFamily, Categorical\n",
    "\n",
    "def build_fullcov_gmm(weights, means, L, index=0):\n",
    "    \"\"\"\n",
    "    weights: (B, K)\n",
    "    means: (B, K, d)\n",
    "    L:     (B, K, d, d)\n",
    "    Returns: GMM over theta ∈ ℝᵈ\n",
    "    \"\"\"\n",
    "    pi = weights[index]   # (K,)\n",
    "    mu = means[index]     # (K, d)\n",
    "    L_k = L[index]        # (K, d, d)\n",
    "    K, d = mu.shape\n",
    "\n",
    "    covs = torch.matmul(L_k, L_k.transpose(-1, -2))  # (K, d, d)\n",
    "    mvn = MultivariateNormal(loc=mu, covariance_matrix=covs)  # batched\n",
    "    gmm = MixtureSameFamily(Categorical(probs=pi), mvn)\n",
    "    return gmm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "19ff1032-4e04-4766-a2b0-8a3e44a0aa9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions import MultivariateNormal, Categorical, MixtureSameFamily\n",
    "\n",
    "def gmm_log_likelihood_loss_fullcov_batched(weights, means, L, targets):\n",
    "    \"\"\"\n",
    "    weights: (B, K)\n",
    "    means:   (B, K, d)\n",
    "    L:       (B, K, d, d)\n",
    "    targets: (B, d)\n",
    "    \"\"\"\n",
    "    B, K, d = means.shape\n",
    "\n",
    "    # Compute covariance matrices (B, K, d, d)\n",
    "    covs = L @ L.transpose(-1, -2)\n",
    "\n",
    "    # Build batched multivariate normal: shape (B, K, d)\n",
    "    mvn = MultivariateNormal(loc=means, covariance_matrix=covs)\n",
    "\n",
    "    # Build categorical over components (B, K)\n",
    "    mix = Categorical(probs=weights)\n",
    "\n",
    "    # Mixture of Gaussians: one per batch element\n",
    "    gmm = MixtureSameFamily(mix, mvn)\n",
    "\n",
    "    # Compute -log p(theta | x)\n",
    "    nll = -gmm.log_prob(targets)  # shape (B,)\n",
    "    return nll.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9b87af44-39bc-48f6-b943-b5fd7b5743ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MambaDensityEstimator(seq_len=seq_len, d_model=d_model, state_size=state_size, batch_size=BATCH_SIZE, theta_dim=theta_dim, device='cuda:1').to(device)\n",
    "criterion = gmm_log_likelihood_loss_fullcov_batched\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# Training loop\n",
    "def train():\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        # Training\n",
    "        for inputs, targets in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS} - Training\"):\n",
    "            optimizer.zero_grad()\n",
    "            weights, means, stds = model(inputs.to(device))\n",
    "            loss = gmm_log_likelihood_loss_fullcov_batched(weights, means, stds, targets.to(device))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            \n",
    "        epoch_train_loss = running_loss / len(train_loader.dataset)\n",
    "        train_losses.append(epoch_train_loss)\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        running_val_loss = 0.0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{EPOCHS} - Validation\"):\n",
    "                inputs = inputs.to(device)\n",
    "                targets = targets.to(device)\n",
    "                \n",
    "                weights, means, stds = model(inputs.to(device))\n",
    "                loss = gmm_log_likelihood_loss_fullcov_batched(weights, means, stds, targets.to(device))\n",
    "                \n",
    "                running_val_loss += loss.item() * inputs.size(0)\n",
    "                \n",
    "        epoch_val_loss = running_val_loss / len(val_loader.dataset)\n",
    "        val_losses.append(epoch_val_loss)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{EPOCHS}, \"\n",
    "              f\"Train Loss: {epoch_train_loss:.4f}, \"\n",
    "              f\"Val Loss: {epoch_val_loss:.4f}\")\n",
    "        \n",
    "        # Save model checkpoint\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'train_loss': epoch_train_loss,\n",
    "                'val_loss': epoch_val_loss,\n",
    "            }, f'mamba_checkpoint_epoch_{epoch+1}.pt')\n",
    "    \n",
    "    return train_losses, val_losses\n",
    "\n",
    "# Plot training and validation loss\n",
    "def plot_loss(train_losses, val_losses):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(train_losses, label='Training Loss')\n",
    "    plt.plot(val_losses, label='Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig('loss_plot.png')\n",
    "    plt.close()\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "def evaluate():\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    all_outputs = []\n",
    "    all_targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in tqdm(val_loader, desc=\"Evaluating\"):\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            weights, means, stds = model(inputs.to(device))\n",
    "            loss = gmm_log_likelihood_loss_fullcov_batched(weights, means, stds, targets.to(device))\n",
    "            \n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "            \n",
    "    \n",
    "    # Calculate average loss\n",
    "    avg_val_loss = val_loss / len(val_loader.dataset)\n",
    "    print(f\"Validation Loss: {avg_val_loss:.4f}\")\n",
    "        \n",
    "    return avg_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2a25d19c-fc42-4f73-a9b5-5a2407ea1cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 - Training: 100%|██████████| 900/900 [01:00<00:00, 14.76it/s]\n",
      "Epoch 1/5 - Validation: 100%|██████████| 100/100 [00:00<00:00, 289.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Train Loss: 1.5111, Val Loss: -1.7910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 - Training: 100%|██████████| 900/900 [01:05<00:00, 13.65it/s]\n",
      "Epoch 2/5 - Validation: 100%|██████████| 100/100 [00:00<00:00, 288.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5, Train Loss: -1.8157, Val Loss: -1.9092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 - Training: 100%|██████████| 900/900 [01:05<00:00, 13.82it/s]\n",
      "Epoch 3/5 - Validation: 100%|██████████| 100/100 [00:00<00:00, 289.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5, Train Loss: -1.8673, Val Loss: -1.8882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 - Training: 100%|██████████| 900/900 [01:03<00:00, 14.22it/s]\n",
      "Epoch 4/5 - Validation: 100%|██████████| 100/100 [00:00<00:00, 290.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5, Train Loss: -1.8858, Val Loss: -1.9092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 - Training: 100%|██████████| 900/900 [01:03<00:00, 14.21it/s]\n",
      "Epoch 5/5 - Validation: 100%|██████████| 100/100 [00:00<00:00, 289.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5, Train Loss: -1.9041, Val Loss: -1.9609\n",
      "\n",
      "Evaluating model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 100/100 [00:00<00:00, 290.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: -1.9609\n",
      "Training and evaluation completed. Model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(\"Starting training...\")\n",
    "    train_losses, val_losses = train()\n",
    "    plot_loss(train_losses, val_losses)\n",
    "    \n",
    "    print(\"\\nEvaluating model...\")\n",
    "    avg_val_loss = evaluate()\n",
    "    \n",
    "    print(\"Training and evaluation completed. Model saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1d9d2de0-3220-4785-83ab-b7a50745172a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions import Categorical, MultivariateNormal, MixtureSameFamily\n",
    "\n",
    "def get_gmm_distribution(model, x, index=0):\n",
    "    \"\"\"\n",
    "    Constructs the full-covariance Gaussian Mixture p(θ | x) for a specific input sample.\n",
    "\n",
    "    Args:\n",
    "        model: your trained MambaDensityEstimator\n",
    "        x: input tensor of shape (B, seq_len, d_model)\n",
    "        index: which batch element to return the distribution for\n",
    "\n",
    "    Returns:\n",
    "        gmm: torch.distributions.MixtureSameFamily over θ ∈ ℝ^d\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        weights, means, L = model(x)  # (B, K), (B, K, d), (B, K, d, d)\n",
    "\n",
    "    pi = weights[index]    # (K,)\n",
    "    mu = means[index]      # (K, d)\n",
    "    L_k = L[index]         # (K, d, d)\n",
    "\n",
    "    cov = L_k @ L_k.transpose(-1, -2)  # (K, d, d)\n",
    "\n",
    "    mvn = MultivariateNormal(loc=mu, covariance_matrix=cov)  # batched over K\n",
    "    mix = Categorical(probs=pi)\n",
    "\n",
    "    return MixtureSameFamily(mix, mvn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "aebec648-3b8f-422c-8727-bc1fab9d8699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1.7406, 0.0115, 0.6471, 0.7088, 0.0118]),\n",
       " tensor([1.5052, 0.7322, 0.7539, 0.4267, 0.0146], device='cuda:1'))"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "k=901\n",
    "\n",
    "x_single = val_dataset[k,][0].to(device)\n",
    "x_single = x_single.unsqueeze(0)  # becomes shape: (1, seq_len, d_model)\n",
    "gmm = get_gmm_distribution(model, x_single)  # index defaults to 0\n",
    "\n",
    "theta = val_dataset[k,][1]\n",
    "\n",
    "samples = gmm.sample((1000,))\n",
    "\n",
    "plt.hist(samples[:,1].cpu())\n",
    "theta, samples.mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de96e03e-3819-4df9-b1c0-58873c7b865a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 10/10 [00:00<00:00, 200.52it/s]\n",
      "Evaluating: 100%|██████████| 10/10 [00:00<00:00, 200.74it/s]\n",
      "Evaluating: 100%|██████████| 10/10 [00:00<00:00, 202.06it/s]\n"
     ]
    }
   ],
   "source": [
    "from torch.distributions import MultivariateNormal, Categorical, MixtureSameFamily\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "def test_mamba(sim, model, device, batch_size, theta_dim, num_samples=1000):\n",
    "    # Load and prepare test data\n",
    "    test_x = torch.load(f'test_sims/test_x_{sim}.pt')          # shape: (N, L)\n",
    "    test_x = test_x.unsqueeze(-1) if test_x.ndim == 2 else test_x  # shape: (N, L, 1)\n",
    "    test_theta = torch.load(f'test_sims/test_theta_{sim}.pt')  # shape: (N, d)\n",
    "\n",
    "    test_dataset = TensorDataset(test_x, test_theta)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    all_samples = []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "            inputs = inputs.to(device)\n",
    "            weights, means, L = model(inputs)  # shapes: (B, K), (B, K, d), (B, K, d, d)\n",
    "\n",
    "            # Compute covariances from Cholesky\n",
    "            covs = L @ L.transpose(-1, -2)  # (B, K, d, d)\n",
    "\n",
    "            # Create batched multivariate normal and mixture\n",
    "            mvn = MultivariateNormal(loc=means, covariance_matrix=covs)\n",
    "            mix = Categorical(probs=weights)\n",
    "            gmm = MixtureSameFamily(mix, mvn)\n",
    "\n",
    "            # Sample from each posterior p(θ | x_i)\n",
    "            samples = gmm.sample((num_samples,))  # (num_samples, B, d)\n",
    "            all_samples.append(samples)           # list of (num_samples, B, d)\n",
    "\n",
    "    # Concatenate across batches → (num_samples, N, d)\n",
    "    all_samples = torch.cat(all_samples, dim=1)\n",
    "\n",
    "    # Save and return\n",
    "    torch.save(all_samples, f'test_sims/samples_{sim}_mamba_de_full.pt')\n",
    "    return all_samples\n",
    "\n",
    "for sim in ['WF', 'WF_DFE', 'WF_bottleneck']:\n",
    "    samples = test_mamba(\n",
    "        sim=sim,\n",
    "        model=model,\n",
    "        device='cuda:1',\n",
    "        batch_size=100,\n",
    "        theta_dim=2,     \n",
    "        num_samples=1000\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414a3214-f1b9-43fa-af4a-5334fac07a4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913a4403-b771-40f1-9c10-9cf205d72acc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
