{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e24bb1a-6448-43d0-8316-c818dd6e9064",
   "metadata": {},
   "source": [
    "# Data generation for all simulators - train + test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0f030c2-1bc7-45d9-a687-f69e4f7fbcfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evo_models import WF, combined_WF_full\n",
    "from inference_utils import get_prior, get_prior_combined\n",
    "from sbi.inference import NPE, NLE, NRE, NPSE\n",
    "from sbi.utils.user_input_checks import (\n",
    "    check_sbi_inputs,\n",
    "    process_prior,\n",
    "    process_simulator,\n",
    ")\n",
    "\n",
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# Define the priors\n",
    "prior = get_prior()\n",
    "prior_combined = get_prior_combined()\n",
    "# Define the simulator\n",
    "def simulator(theta):\n",
    "    s1, m1, s2, m2, s12, m12, m21 = 10**np.array(theta)\n",
    "    N = int(1e8)\n",
    "    G = 200\n",
    "    res = WF(s1, m1, s2, m2, s12, m12, m21, N, G) # replace with combined_WF_full for 2-mutation model\n",
    "    return torch.tensor(res)\n",
    "\n",
    "# Simulate using sbi's interface\n",
    "\n",
    "# Check prior, return PyTorch prior.\n",
    "prior, num_parameters, prior_returns_numpy = process_prior(prior_combined)\n",
    "\n",
    "# Check simulator, returns PyTorch simulator able to simulate batches.\n",
    "simulator = process_simulator(simulator, prior, prior_returns_numpy)\n",
    "\n",
    "# Consistency check after making ready for sbi.\n",
    "check_sbi_inputs(simulator, prior)\n",
    "\n",
    "num_simulations = 100_000\n",
    "theta = prior.sample((num_simulations,))\n",
    "x = simulator(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bd60b4f-8a31-48ef-aefa-5471508c69f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "torch.save(theta, \"test_sims/theta.pt\")\n",
    "torch.save(x, \"test_sims/x.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68d99ae-f1a2-40c0-a2ec-fe1db9d5217f",
   "metadata": {},
   "source": [
    "## Generate test simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d197bfa-35f8-4596-bf15-6ffca2a873fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sbi.utils import BoxUniform\n",
    "from inference_utils import get_prior, get_prior_combined, get_dist\n",
    "from evo_models import WF, WF_bottleneck, WF_DFE, combined_WF, combined_WF_full\n",
    "\n",
    "# Define the prior and constants\n",
    "prior = get_prior()\n",
    "N = int(1e8)\n",
    "G = 200\n",
    "\n",
    "# Define the simulator\n",
    "def simulator(model, theta):\n",
    "    s = 10**theta[0].item()\n",
    "    mu = 10**theta[1].item()\n",
    "    if model == 'WF':\n",
    "        res = WF(s, mu, N, G)\n",
    "    elif model == 'WF_bottleneck':\n",
    "        bottlenecks = [10*(i+1) for i in range(G//10)]\n",
    "        N_bottleneck = N//1000\n",
    "        bot_dict = {b: N_bottleneck for b in bottlenecks}\n",
    "        res = WF_bottleneck(s, mu, N, G, bot_dict, seed=None) # Run the bottleneck model\n",
    "    elif model == 'WF_DFE':\n",
    "        dist = get_dist(s)\n",
    "        res = WF_DFE(mu, N, G, dist)\n",
    "    return torch.tensor(res)\n",
    "\n",
    "def export_sims(model, num_simulations):\n",
    "    x_export = torch.empty(num_simulations, G//10)\n",
    "    thetas = prior.sample((num_simulations,))\n",
    "    for i in range(len(thetas)):\n",
    "        theta = thetas[i]\n",
    "        x_export[i,:] = simulator(model, theta)\n",
    "    torch.save(x_export,f'test_sims/test_x_{model}.pt')\n",
    "    torch.save(thetas,f'test_sims/test_theta_{model}.pt')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # export_sims('WF', 1000)\n",
    "    # export_sims('WF_bottleneck', 1000)\n",
    "    # export_sims('WF_DFE', 1000)\n",
    "    # export_sims('combined_WF', 1000)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39f86f8d-843f-4b2e-aa70-272d744f6baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-mutation model\n",
    "\n",
    "prior_combined = get_prior_combined()\n",
    "x_export = torch.empty(1000, G//10*2)\n",
    "thetas = prior_combined.sample((1000,))\n",
    "for i in range(len(thetas)):\n",
    "    theta = thetas[i]\n",
    "    s1, m1, s2, m2, s12, m12, m21 = 10**theta\n",
    "    x_export[i,:] = torch.tensor(combined_WF_full(s1, m1, s2, m2, s12, m12, m21, N, G), dtype=torch.float32)\n",
    "    \n",
    "torch.save(x_export,f'test_sims/test_x_combined.pt')\n",
    "torch.save(thetas,f'test_sims/test_theta_combined.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0923d4e-573c-428b-82b2-f609c2cd7d2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
